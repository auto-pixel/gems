name: gemns_transcript

on:
  schedule:
    - cron: '30 21 * * *'  # Run daily at 10:30 AM UTC (4:00 PM Indian time - UTC+5:30)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 1200

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python 3.12
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.3'
          cache: 'pip'
          check-latest: true

      - name: Install Firefox and GeckoDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y firefox wget
          wget https://github.com/mozilla/geckodriver/releases/download/v0.33.0/geckodriver-v0.33.0-linux64.tar.gz
          sudo tar -xzf geckodriver-*-linux64.tar.gz -C /usr/local/bin
          sudo chmod +x /usr/local/bin/geckodriver
          export PATH="/usr/local/bin:$PATH"
          geckodriver --version
          firefox --version

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          grep -v "firefox-geckodriver" requirements.txt > temp_requirements.txt
          pip install -r temp_requirements.txt

      - name: Setup credentials
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS_JSON }}' > credentials.json
          python -c "
          import json, sys
          try:
              with open('credentials.json', 'r') as f:
                  json.load(f)
              print('âœ“ Google credentials JSON validated successfully')
          except json.JSONDecodeError as e:
              print(f'ERROR: Invalid JSON in credentials file: {e}')
              print('Checking file content:')
              with open('credentials.json', 'r') as f:
                  print(f.read())
              sys.exit(1)
          "
          echo CLAUDE_API_KEY=${{ secrets.CLAUDE_API_KEY }} > .env

      - name: Download proxies
        run: |
          python -c "
          import requests, random, time
          user_agents = [
              'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
              'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0',
              'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15'
          ]
          headers = {'User-Agent': random.choice(user_agents)}
          sources = [
              'https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt',
              'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt',
              'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt'
          ]
          proxies = set()
          for source in sources:
              try:
                  r = requests.get(source, headers=headers, timeout=10)
                  if r.status_code == 200:
                      proxies.update([p for p in r.text.splitlines() if p.strip()])
                      print(f'Downloaded from {source}')
                  time.sleep(random.uniform(1, 3))
              except Exception as e:
                  print(f'Failed: {e}')
          with open('proxies.txt', 'w') as f:
              f.write('\\n'.join(proxies))
          print(f'Saved {len(proxies)} proxies')
          "

      - name: Install ffmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          ffmpeg -version

      - name: Run master script
        run: python transcript_bot.py

      - name: Run post-processing script
        if: always()
        run: python Claude_ai.py

      - name: Run post-processing script
        if: always()
        run: python Winning_creative.py

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: scraping-results
          path: |
            ads_data.json
            logs/
